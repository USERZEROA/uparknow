{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80a4f5e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
      "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0280339b52904536b089035af17e039e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(IntSlider(value=280, continuous_update=False, description='Time (s)', max=316, min=280), Image(â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "from transformers import DetrForObjectDetection, DetrImageProcessor\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model = DetrForObjectDetection.from_pretrained('facebook/detr-resnet-50').to(device)\n",
    "processor = DetrImageProcessor.from_pretrained('facebook/detr-resnet-50')\n",
    "model.eval()\n",
    "\n",
    "\n",
    "video_path = 'Parkng_Lot_Surveillance_Video.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "total_seconds = int(total_frames / fps)\n",
    "\n",
    "\n",
    "initial_time = 280\n",
    "initial_frame_number = int(initial_time * fps)\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, initial_frame_number)\n",
    "ret, frame = cap.read()\n",
    "if not ret:\n",
    "    raise ValueError(\"Cannot read the initial frame at 285 seconds.\")\n",
    "\n",
    "image_height = frame.shape[0]\n",
    "\n",
    "\n",
    "with open('flipped_car_coordinates_with_parking_positions.json', 'r') as file:\n",
    "    parking_boxes = json.load(file)\n",
    "\n",
    "for box in parking_boxes:\n",
    "    box[\"y1\"] = image_height - box[\"y1\"]\n",
    "    box[\"y2\"] = image_height - box[\"y2\"]\n",
    "\n",
    "\n",
    "def calculate_iou(boxA, boxB):\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2], boxB[2])\n",
    "    yB = min(boxA[3], boxB[3])\n",
    "\n",
    "    interWidth = max(0, xB - xA)\n",
    "    interHeight = max(0, yB - yA)\n",
    "    interArea = interWidth * interHeight\n",
    "\n",
    "    boxAArea = (boxA[2] - boxA[0]) * (boxA[3] - boxA[1])\n",
    "    boxBArea = (boxB[2] - boxB[0]) * (boxB[3] - boxB[1])\n",
    "    iou = interArea / float(boxAArea + boxBArea - interArea)\n",
    "    \n",
    "    return iou\n",
    "\n",
    "parking_status_output = widgets.Output()\n",
    "\n",
    "image_widget = widgets.Image(format='jpeg')\n",
    "\n",
    "def update_frame(change):\n",
    "    time_in_seconds = time_slider.value\n",
    "    frame_number = int(fps * time_in_seconds)\n",
    "\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number)\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret or frame is None:\n",
    "        print(f\"Error: Cannot read frame at {time_in_seconds} seconds.\")\n",
    "        return\n",
    "\n",
    "    image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "    inputs = processor(images=image, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    logits = outputs.logits[0].cpu()\n",
    "    boxes = outputs.pred_boxes[0].cpu()\n",
    "\n",
    "    probas = logits.softmax(-1)\n",
    "    keep = probas.max(-1).values > 0.5\n",
    "\n",
    "    for parking_box in parking_boxes:\n",
    "        x1 = int(parking_box[\"x1\"])\n",
    "        y1 = int(parking_box[\"y1\"])\n",
    "        x2 = int(parking_box[\"x2\"])\n",
    "        y2 = int(parking_box[\"y2\"])\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), color=(255, 0, 0), thickness=2)\n",
    "        cv2.putText(frame, f'Row: {parking_box[\"row\"]}, Col: {parking_box[\"column\"]}', (x1, y1 - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1)\n",
    "\n",
    "    detected_boxes = []\n",
    "    for box, cls in zip(boxes[keep], probas[keep]):\n",
    "        category_id = cls.argmax().item()\n",
    "        if category_id == 3:  # 3 is car\n",
    "            x_center, y_center, width, height = box.numpy()\n",
    "            x1 = int((x_center - width / 2) * frame.shape[1])\n",
    "            y1 = int((y_center - height / 2) * frame.shape[0])\n",
    "            x2 = int((x_center + width / 2) * frame.shape[1])\n",
    "            y2 = int((y_center + height / 2) * frame.shape[0])\n",
    "            detected_boxes.append((x1, y1, x2, y2))\n",
    "\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), color=(0, 255, 0), thickness=2)\n",
    "            cv2.putText(frame, 'Car', (x1, y1 - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
    "\n",
    "    parking_status = [\n",
    "        {\"row\": row, \"column\": col, \"parked\": False}\n",
    "        for row in range(1, 3)\n",
    "        for col in range(1, 14)\n",
    "    ]\n",
    "\n",
    "    for detected_box in detected_boxes:\n",
    "        for parking_box in parking_boxes:\n",
    "            parking_box_coords = [parking_box[\"x1\"], parking_box[\"y1\"], parking_box[\"x2\"], parking_box[\"y2\"]]\n",
    "            iou = calculate_iou(detected_box, parking_box_coords)\n",
    "            if iou > 0.5:\n",
    "                row, column = parking_box[\"row\"], parking_box[\"column\"]\n",
    "                for status in parking_status:\n",
    "                    if status[\"row\"] == row and status[\"column\"] == column:\n",
    "                        status[\"parked\"] = True\n",
    "\n",
    "    with parking_status_output:\n",
    "        clear_output(wait=True)\n",
    "        print(parking_status)\n",
    "\n",
    "    ret, buffer = cv2.imencode('.jpg', frame)\n",
    "    if ret:\n",
    "        image_widget.value = buffer.tobytes()\n",
    "\n",
    "time_slider = widgets.IntSlider(value=initial_time, min=initial_time, max=total_seconds, step=1, description=\"Time (s)\", continuous_update=False)\n",
    "time_slider.observe(update_frame, names='value')\n",
    "\n",
    "display(widgets.VBox([time_slider, image_widget, parking_status_output]))\n",
    "update_frame(None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a95ba55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
